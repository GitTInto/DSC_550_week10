{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import regex as re\n",
    "import requests\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load data into a dataframe\n",
    "addr = \"/Users/tthekkum/Documents/LnD/BV/550_DataMining/Second time/week9_10/categorized-comments.jsonl\"\n",
    "data = pd.read_json(addr ,lines = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tthekkum/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tthekkum/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tthekkum/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/tthekkum/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "getattr(ssl, '_create_unverified_context', None)):\n",
    " ssl._create_default_https_context = ssl._create_unverified_context\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "      cat                                                txt  \\\n0  sports  Barely better than Gabbert? He was significant...   \n1  sports  Fuck the ducks and the Angels! But welcome to ...   \n2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...   \n3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)   \n4  sports                                      No!! NOO!!!!!   \n\n                                      part_of_speech  \n0  [(Barely, RB), (better, JJR), (than, IN), (Gab...  \n1  [(Fuck, IN), (the, DT), (ducks, NNS), (and, CC...  \n2  [(Should, MD), (have, VB), (drafted, VBN), (mo...  \n3  [([, NN), (Done, NNP), (], NNP), ((, (), (http...  \n4  [(No, DT), (!, .), (!, .), (NOO, NN), (!, .), ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat</th>\n      <th>txt</th>\n      <th>part_of_speech</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sports</td>\n      <td>Barely better than Gabbert? He was significant...</td>\n      <td>[(Barely, RB), (better, JJR), (than, IN), (Gab...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sports</td>\n      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n      <td>[(Fuck, IN), (the, DT), (ducks, NNS), (and, CC...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sports</td>\n      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n      <td>[(Should, MD), (have, VB), (drafted, VBN), (mo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sports</td>\n      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n      <td>[([, NN), (Done, NNP), (], NNP), ((, (), (http...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sports</td>\n      <td>No!! NOO!!!!!</td>\n      <td>[(No, DT), (!, .), (!, .), (NOO, NN), (!, .), ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['part_of_speech']=data['txt'].apply(nltk.word_tokenize).apply(nltk.pos_tag)\n",
    "   # nltk.word_tokenize.data['txt']\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def stemmer(x):\n",
    " stemmer = PorterStemmer()\n",
    " return ' '.join([stemmer.stem(word) for word in x])\n",
    "\n",
    "def lemmatize(x):\n",
    " lemmatizer = WordNetLemmatizer()\n",
    " return ' '.join([lemmatizer.lemmatize(word) for word in x])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#data.cat\n",
    "data['cat_id'] = data['cat'].factorize()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "      cat                                                txt  \\\n0  sports  Barely better than Gabbert? He was significant...   \n1  sports  Fuck the ducks and the Angels! But welcome to ...   \n2  sports  Should have drafted more WRs.\\n\\n- Matt Millen...   \n3  sports            [Done](https://i.imgur.com/2YZ90pm.jpg)   \n4  sports                                      No!! NOO!!!!!   \n\n                                      part_of_speech  cat_id  \\\n0  [(Barely, RB), (better, JJR), (than, IN), (Gab...       0   \n1  [(Fuck, IN), (the, DT), (ducks, NNS), (and, CC...       0   \n2  [(Should, MD), (have, VB), (drafted, VBN), (mo...       0   \n3  [([, NN), (Done, NNP), (], NNP), ((, (), (http...       0   \n4  [(No, DT), (!, .), (!, .), (NOO, NN), (!, .), ...       0   \n\n                                               lemma  \n0  B a r e l y   b e t t e r   t h a n   G a b b ...  \n1  F u c k   t h e   d u c k s   a n d   t h e   ...  \n2  S h o u l d   h a v e   d r a f t e d   m o r ...  \n3  [ D o n e ] ( h t t p s : / / i . i m g u r . ...  \n4                          N o ! !   N O O ! ! ! ! !  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cat</th>\n      <th>txt</th>\n      <th>part_of_speech</th>\n      <th>cat_id</th>\n      <th>lemma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sports</td>\n      <td>Barely better than Gabbert? He was significant...</td>\n      <td>[(Barely, RB), (better, JJR), (than, IN), (Gab...</td>\n      <td>0</td>\n      <td>B a r e l y   b e t t e r   t h a n   G a b b ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sports</td>\n      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n      <td>[(Fuck, IN), (the, DT), (ducks, NNS), (and, CC...</td>\n      <td>0</td>\n      <td>F u c k   t h e   d u c k s   a n d   t h e   ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sports</td>\n      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n      <td>[(Should, MD), (have, VB), (drafted, VBN), (mo...</td>\n      <td>0</td>\n      <td>S h o u l d   h a v e   d r a f t e d   m o r ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sports</td>\n      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n      <td>[([, NN), (Done, NNP), (], NNP), ((, (), (http...</td>\n      <td>0</td>\n      <td>[ D o n e ] ( h t t p s : / / i . i m g u r . ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>sports</td>\n      <td>No!! NOO!!!!!</td>\n      <td>[(No, DT), (!, .), (!, .), (NOO, NN), (!, .), ...</td>\n      <td>0</td>\n      <td>N o ! !   N O O ! ! ! ! !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemma'] = data['txt'].map(lemmatize)\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X = data['txt']\n",
    "y = data['cat']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 13)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "outputs": [],
   "source": [
    "from transformer import TextNormalizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "pipe_mnnb = Pipeline(steps = [('tf', TfidfVectorizer()), ('ann', MLPClassifier(hidden_layer_sizes=[50,15], verbose=True))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69224092\n",
      "Iteration 2, loss = 0.68196447\n",
      "Iteration 3, loss = 0.67200198\n",
      "Iteration 4, loss = 0.66234449\n",
      "Iteration 5, loss = 0.65304912\n",
      "Iteration 6, loss = 0.64414201\n",
      "Iteration 7, loss = 0.63557254\n",
      "Iteration 8, loss = 0.62736778\n",
      "Iteration 9, loss = 0.61984760\n",
      "Iteration 10, loss = 0.61291529\n",
      "Iteration 11, loss = 0.60666067\n",
      "Iteration 12, loss = 0.60108675\n",
      "Iteration 13, loss = 0.59607743\n",
      "Iteration 14, loss = 0.59147426\n",
      "Iteration 15, loss = 0.58719139\n",
      "Iteration 16, loss = 0.58319645\n",
      "Iteration 17, loss = 0.57935167\n",
      "Iteration 18, loss = 0.57563395\n",
      "Iteration 19, loss = 0.57210697\n",
      "Iteration 20, loss = 0.56874518\n",
      "Iteration 21, loss = 0.56553478\n",
      "Iteration 22, loss = 0.56255802\n",
      "Iteration 23, loss = 0.55975011\n",
      "Iteration 24, loss = 0.55705748\n",
      "Iteration 25, loss = 0.55444664\n",
      "Iteration 26, loss = 0.55194533\n",
      "Iteration 27, loss = 0.54953771\n",
      "Iteration 28, loss = 0.54722016\n",
      "Iteration 29, loss = 0.54493809\n",
      "Iteration 30, loss = 0.54269849\n",
      "Iteration 31, loss = 0.54043555\n",
      "Iteration 32, loss = 0.53811164\n",
      "Iteration 33, loss = 0.53570185\n",
      "Iteration 34, loss = 0.53325232\n",
      "Iteration 35, loss = 0.53062721\n",
      "Iteration 36, loss = 0.52775966\n",
      "Iteration 37, loss = 0.52465543\n",
      "Iteration 38, loss = 0.52124920\n",
      "Iteration 39, loss = 0.51760382\n",
      "Iteration 40, loss = 0.51363531\n",
      "Iteration 41, loss = 0.50928110\n",
      "Iteration 42, loss = 0.50460630\n",
      "Iteration 43, loss = 0.49969639\n",
      "Iteration 44, loss = 0.49445017\n",
      "Iteration 45, loss = 0.48891526\n",
      "Iteration 46, loss = 0.48315376\n",
      "Iteration 47, loss = 0.47716021\n",
      "Iteration 48, loss = 0.47096738\n",
      "Iteration 49, loss = 0.46459997\n",
      "Iteration 50, loss = 0.45807356\n",
      "Iteration 51, loss = 0.45143696\n",
      "Iteration 52, loss = 0.44472085\n",
      "Iteration 53, loss = 0.43793648\n",
      "Iteration 54, loss = 0.43102776\n",
      "Iteration 55, loss = 0.42406920\n",
      "Iteration 56, loss = 0.41706430\n",
      "Iteration 57, loss = 0.40999445\n",
      "Iteration 58, loss = 0.40289982\n",
      "Iteration 59, loss = 0.39578727\n",
      "Iteration 60, loss = 0.38865563\n",
      "Iteration 61, loss = 0.38151539\n",
      "Iteration 62, loss = 0.37436629\n",
      "Iteration 63, loss = 0.36721861\n",
      "Iteration 64, loss = 0.36006508\n",
      "Iteration 65, loss = 0.35291190\n",
      "Iteration 66, loss = 0.34576025\n",
      "Iteration 67, loss = 0.33860348\n",
      "Iteration 68, loss = 0.33144103\n",
      "Iteration 69, loss = 0.32428287\n",
      "Iteration 70, loss = 0.31712444\n",
      "Iteration 71, loss = 0.30996124\n",
      "Iteration 72, loss = 0.30280212\n",
      "Iteration 73, loss = 0.29565858\n",
      "Iteration 74, loss = 0.28856248\n",
      "Iteration 75, loss = 0.28152053\n",
      "Iteration 76, loss = 0.27454059\n",
      "Iteration 77, loss = 0.26763263\n",
      "Iteration 78, loss = 0.26080262\n",
      "Iteration 79, loss = 0.25406181\n",
      "Iteration 80, loss = 0.24741718\n",
      "Iteration 81, loss = 0.24086737\n",
      "Iteration 82, loss = 0.23441655\n",
      "Iteration 83, loss = 0.22807177\n",
      "Iteration 84, loss = 0.22183996\n",
      "Iteration 85, loss = 0.21572107\n",
      "Iteration 86, loss = 0.20971510\n",
      "Iteration 87, loss = 0.20382057\n",
      "Iteration 88, loss = 0.19804117\n",
      "Iteration 89, loss = 0.19237014\n",
      "Iteration 90, loss = 0.18681549\n",
      "Iteration 91, loss = 0.18136397\n",
      "Iteration 92, loss = 0.17602725\n",
      "Iteration 93, loss = 0.17081189\n",
      "Iteration 94, loss = 0.16572247\n",
      "Iteration 95, loss = 0.16075973\n",
      "Iteration 96, loss = 0.15592588\n",
      "Iteration 97, loss = 0.15121819\n",
      "Iteration 98, loss = 0.14663628\n",
      "Iteration 99, loss = 0.14218115\n",
      "Iteration 100, loss = 0.13784743\n",
      "Iteration 101, loss = 0.13363311\n",
      "Iteration 102, loss = 0.12952866\n",
      "Iteration 103, loss = 0.12553110\n",
      "Iteration 104, loss = 0.12162355\n",
      "Iteration 105, loss = 0.11780332\n",
      "Iteration 106, loss = 0.11407077\n",
      "Iteration 107, loss = 0.11042916\n",
      "Iteration 108, loss = 0.10687676\n",
      "Iteration 109, loss = 0.10341269\n",
      "Iteration 110, loss = 0.10003861\n",
      "Iteration 111, loss = 0.09675670\n",
      "Iteration 112, loss = 0.09356549\n",
      "Iteration 113, loss = 0.09045326\n",
      "Iteration 114, loss = 0.08742337\n",
      "Iteration 115, loss = 0.08448733\n",
      "Iteration 116, loss = 0.08164120\n",
      "Iteration 117, loss = 0.07888670\n",
      "Iteration 118, loss = 0.07622298\n",
      "Iteration 119, loss = 0.07364712\n",
      "Iteration 120, loss = 0.07115960\n",
      "Iteration 121, loss = 0.06876084\n",
      "Iteration 122, loss = 0.06644922\n",
      "Iteration 123, loss = 0.06422260\n",
      "Iteration 124, loss = 0.06207877\n",
      "Iteration 125, loss = 0.06001542\n",
      "Iteration 126, loss = 0.05803018\n",
      "Iteration 127, loss = 0.05612059\n",
      "Iteration 128, loss = 0.05428427\n",
      "Iteration 129, loss = 0.05251869\n",
      "Iteration 130, loss = 0.05082138\n",
      "Iteration 131, loss = 0.04918992\n",
      "Iteration 132, loss = 0.04762191\n",
      "Iteration 133, loss = 0.04611497\n",
      "Iteration 134, loss = 0.04466680\n",
      "Iteration 135, loss = 0.04327513\n",
      "Iteration 136, loss = 0.04193774\n",
      "Iteration 137, loss = 0.04065249\n",
      "Iteration 138, loss = 0.03941730\n",
      "Iteration 139, loss = 0.03823011\n",
      "Iteration 140, loss = 0.03708898\n",
      "Iteration 141, loss = 0.03599199\n",
      "Iteration 142, loss = 0.03493731\n",
      "Iteration 143, loss = 0.03392318\n",
      "Iteration 144, loss = 0.03294791\n",
      "Iteration 145, loss = 0.03200984\n",
      "Iteration 146, loss = 0.03110735\n",
      "Iteration 147, loss = 0.03023896\n",
      "Iteration 148, loss = 0.02940322\n",
      "Iteration 149, loss = 0.02859875\n",
      "Iteration 150, loss = 0.02782421\n",
      "Iteration 151, loss = 0.02707833\n",
      "Iteration 152, loss = 0.02635989\n",
      "Iteration 153, loss = 0.02566773\n",
      "Iteration 154, loss = 0.02500065\n",
      "Iteration 155, loss = 0.02435749\n",
      "Iteration 156, loss = 0.02373728\n",
      "Iteration 157, loss = 0.02313917\n",
      "Iteration 158, loss = 0.02256204\n",
      "Iteration 159, loss = 0.02200520\n",
      "Iteration 160, loss = 0.02146773\n",
      "Iteration 161, loss = 0.02094885\n",
      "Iteration 162, loss = 0.02044776\n",
      "Iteration 163, loss = 0.01996372\n",
      "Iteration 164, loss = 0.01949603\n",
      "Iteration 165, loss = 0.01904402\n",
      "Iteration 166, loss = 0.01860706\n",
      "Iteration 167, loss = 0.01818452\n",
      "Iteration 168, loss = 0.01777583\n",
      "Iteration 169, loss = 0.01738039\n",
      "Iteration 170, loss = 0.01699766\n",
      "Iteration 171, loss = 0.01662715\n",
      "Iteration 172, loss = 0.01626835\n",
      "Iteration 173, loss = 0.01592081\n",
      "Iteration 174, loss = 0.01558409\n",
      "Iteration 175, loss = 0.01525776\n",
      "Iteration 176, loss = 0.01494144\n",
      "Iteration 177, loss = 0.01463472\n",
      "Iteration 178, loss = 0.01433724\n",
      "Iteration 179, loss = 0.01404865\n",
      "Iteration 180, loss = 0.01376857\n",
      "Iteration 181, loss = 0.01349672\n",
      "Iteration 182, loss = 0.01323279\n",
      "Iteration 183, loss = 0.01297648\n",
      "Iteration 184, loss = 0.01272749\n",
      "Iteration 185, loss = 0.01248556\n",
      "Iteration 186, loss = 0.01225038\n",
      "Iteration 187, loss = 0.01202171\n",
      "Iteration 188, loss = 0.01179934\n",
      "Iteration 189, loss = 0.01158306\n",
      "Iteration 190, loss = 0.01137266\n",
      "Iteration 191, loss = 0.01116793\n",
      "Iteration 192, loss = 0.01096867\n",
      "Iteration 193, loss = 0.01077470\n",
      "Iteration 194, loss = 0.01058583\n",
      "Iteration 195, loss = 0.01040185\n",
      "Iteration 196, loss = 0.01022242\n",
      "Iteration 197, loss = 0.01004752\n",
      "Iteration 198, loss = 0.00987693\n",
      "Iteration 199, loss = 0.00971059\n",
      "Iteration 200, loss = 0.00954833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tthekkum/PycharmProjects/DS550/venv/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('tf', TfidfVectorizer()),\n                ('ann',\n                 MLPClassifier(hidden_layer_sizes=[50, 15], verbose=True))])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_mnnb.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "py_pred1 = pipe_mnnb.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,py_pred1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sports       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,py_pred1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, py_pred1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "pgrid_mnnb = {\n",
    " 'tf__max_features' : [10, 20, 30],\n",
    " 'tf__stop_words' : ['english', None],\n",
    " 'tf__ngram_range' : [(1,1),(1,2)],\n",
    " 'tf__use_idf' : [True, False]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "gs_mnnb = GridSearchCV(pipe_mnnb,pgrid_mnnb,cv=5,n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.15402730\n",
      "Iteration 2, loss = 1.14017491\n",
      "Iteration 3, loss = 1.12648248\n",
      "Iteration 4, loss = 1.11288471\n",
      "Iteration 5, loss = 1.09936465\n",
      "Iteration 6, loss = 1.08592896\n",
      "Iteration 7, loss = 1.07257327\n",
      "Iteration 8, loss = 1.05928086\n",
      "Iteration 9, loss = 1.04607559\n",
      "Iteration 10, loss = 1.03238384\n",
      "Iteration 11, loss = 1.01879647\n",
      "Iteration 12, loss = 1.00527827\n",
      "Iteration 13, loss = 0.99183205\n",
      "Iteration 14, loss = 0.97846468\n",
      "Iteration 15, loss = 0.96529007\n",
      "Iteration 16, loss = 0.95221394\n",
      "Iteration 17, loss = 0.93931488\n",
      "Iteration 18, loss = 0.92656785\n",
      "Iteration 19, loss = 0.91394823\n",
      "Iteration 20, loss = 0.90153811\n",
      "Iteration 21, loss = 0.88937183\n",
      "Iteration 22, loss = 0.87737377\n",
      "Iteration 23, loss = 0.86548933\n",
      "Iteration 24, loss = 0.85368036\n",
      "Iteration 25, loss = 0.84187915\n",
      "Iteration 26, loss = 0.83000097\n",
      "Iteration 27, loss = 0.81816375\n",
      "Iteration 28, loss = 0.80633475\n",
      "Iteration 29, loss = 0.79447113\n",
      "Iteration 30, loss = 0.78263069\n",
      "Iteration 31, loss = 0.77081291\n",
      "Iteration 32, loss = 0.75893412\n",
      "Iteration 33, loss = 0.74672880\n",
      "Iteration 34, loss = 0.73379963\n",
      "Iteration 35, loss = 0.72084930\n",
      "Iteration 36, loss = 0.70793287\n",
      "Iteration 37, loss = 0.69497528\n",
      "Iteration 38, loss = 0.68198402\n",
      "Iteration 39, loss = 0.66907421\n",
      "Iteration 40, loss = 0.65626292\n",
      "Iteration 41, loss = 0.64327142\n",
      "Iteration 42, loss = 0.63010094\n",
      "Iteration 43, loss = 0.61703218\n",
      "Iteration 44, loss = 0.60404791\n",
      "Iteration 45, loss = 0.59117545\n",
      "Iteration 46, loss = 0.57843384\n",
      "Iteration 47, loss = 0.56583348\n",
      "Iteration 48, loss = 0.55334870\n",
      "Iteration 49, loss = 0.54099894\n",
      "Iteration 50, loss = 0.52883455\n",
      "Iteration 51, loss = 0.51688822\n",
      "Iteration 52, loss = 0.50541510\n",
      "Iteration 53, loss = 0.49414548\n",
      "Iteration 54, loss = 0.48303203\n",
      "Iteration 55, loss = 0.47207920\n",
      "Iteration 56, loss = 0.46129662\n",
      "Iteration 57, loss = 0.45069315\n",
      "Iteration 58, loss = 0.44022620\n",
      "Iteration 59, loss = 0.42991704\n",
      "Iteration 60, loss = 0.41979322\n",
      "Iteration 61, loss = 0.40985071\n",
      "Iteration 62, loss = 0.40006775\n",
      "Iteration 63, loss = 0.39044942\n",
      "Iteration 64, loss = 0.38114498\n",
      "Iteration 65, loss = 0.37216406\n",
      "Iteration 66, loss = 0.36332145\n",
      "Iteration 67, loss = 0.35458248\n",
      "Iteration 68, loss = 0.34602833\n",
      "Iteration 69, loss = 0.33740044\n",
      "Iteration 70, loss = 0.32883794\n",
      "Iteration 71, loss = 0.32041942\n",
      "Iteration 72, loss = 0.31214270\n",
      "Iteration 73, loss = 0.30401175\n",
      "Iteration 74, loss = 0.29604683\n",
      "Iteration 75, loss = 0.28825317\n",
      "Iteration 76, loss = 0.28062515\n",
      "Iteration 77, loss = 0.27313571\n",
      "Iteration 78, loss = 0.26575912\n",
      "Iteration 79, loss = 0.25853706\n",
      "Iteration 80, loss = 0.25149164\n",
      "Iteration 81, loss = 0.24462439\n",
      "Iteration 82, loss = 0.23792970\n",
      "Iteration 83, loss = 0.23141390\n",
      "Iteration 84, loss = 0.22500585\n",
      "Iteration 85, loss = 0.21874037\n",
      "Iteration 86, loss = 0.21266252\n",
      "Iteration 87, loss = 0.20675660\n",
      "Iteration 88, loss = 0.20101489\n",
      "Iteration 89, loss = 0.19543701\n",
      "Iteration 90, loss = 0.19001927\n",
      "Iteration 91, loss = 0.18477364\n",
      "Iteration 92, loss = 0.17970299\n",
      "Iteration 93, loss = 0.17475374\n",
      "Iteration 94, loss = 0.16989724\n",
      "Iteration 95, loss = 0.16521560\n",
      "Iteration 96, loss = 0.16067155\n",
      "Iteration 97, loss = 0.15626383\n",
      "Iteration 98, loss = 0.15199154\n",
      "Iteration 99, loss = 0.14785190\n",
      "Iteration 100, loss = 0.14384126\n",
      "Iteration 101, loss = 0.13995622\n",
      "Iteration 102, loss = 0.13619336\n",
      "Iteration 103, loss = 0.13254778\n",
      "Iteration 104, loss = 0.12901595\n",
      "Iteration 105, loss = 0.12559628\n",
      "Iteration 106, loss = 0.12228656\n",
      "Iteration 107, loss = 0.11908463\n",
      "Iteration 108, loss = 0.11598221\n",
      "Iteration 109, loss = 0.11297802\n",
      "Iteration 110, loss = 0.11006850\n",
      "Iteration 111, loss = 0.10725028\n",
      "Iteration 112, loss = 0.10452128\n",
      "Iteration 113, loss = 0.10187833\n",
      "Iteration 114, loss = 0.09931904\n",
      "Iteration 115, loss = 0.09684105\n",
      "Iteration 116, loss = 0.09444073\n",
      "Iteration 117, loss = 0.09211574\n",
      "Iteration 118, loss = 0.08986385\n",
      "Iteration 119, loss = 0.08768145\n",
      "Iteration 120, loss = 0.08556646\n",
      "Iteration 121, loss = 0.08351753\n",
      "Iteration 122, loss = 0.08153218\n",
      "Iteration 123, loss = 0.07960830\n",
      "Iteration 124, loss = 0.07774389\n",
      "Iteration 125, loss = 0.07593687\n",
      "Iteration 126, loss = 0.07418514\n",
      "Iteration 127, loss = 0.07248672\n",
      "Iteration 128, loss = 0.07083971\n",
      "Iteration 129, loss = 0.06924250\n",
      "Iteration 130, loss = 0.06769330\n",
      "Iteration 131, loss = 0.06618998\n",
      "Iteration 132, loss = 0.06473146\n",
      "Iteration 133, loss = 0.06331616\n",
      "Iteration 134, loss = 0.06193307\n",
      "Iteration 135, loss = 0.06057483\n",
      "Iteration 136, loss = 0.05924724\n",
      "Iteration 137, loss = 0.05795115\n",
      "Iteration 138, loss = 0.05668691\n",
      "Iteration 139, loss = 0.05545456\n",
      "Iteration 140, loss = 0.05425380\n",
      "Iteration 141, loss = 0.05308427\n",
      "Iteration 142, loss = 0.05194591\n",
      "Iteration 143, loss = 0.05083827\n",
      "Iteration 144, loss = 0.04976074\n",
      "Iteration 145, loss = 0.04871271\n",
      "Iteration 146, loss = 0.04769344\n",
      "Iteration 147, loss = 0.04670227\n",
      "Iteration 148, loss = 0.04574297\n",
      "Iteration 149, loss = 0.04480592\n",
      "Iteration 150, loss = 0.04389136\n",
      "Iteration 151, loss = 0.04300543\n",
      "Iteration 152, loss = 0.04214308\n",
      "Iteration 153, loss = 0.04130431\n",
      "Iteration 154, loss = 0.04048843\n",
      "Iteration 155, loss = 0.03969483\n",
      "Iteration 156, loss = 0.03892282\n",
      "Iteration 157, loss = 0.03817176\n",
      "Iteration 158, loss = 0.03744031\n",
      "Iteration 159, loss = 0.03672812\n",
      "Iteration 160, loss = 0.03603490\n",
      "Iteration 161, loss = 0.03536013\n",
      "Iteration 162, loss = 0.03470324\n",
      "Iteration 163, loss = 0.03406369\n",
      "Iteration 164, loss = 0.03344095\n",
      "Iteration 165, loss = 0.03283450\n",
      "Iteration 166, loss = 0.03224382\n",
      "Iteration 167, loss = 0.03166842\n",
      "Iteration 168, loss = 0.03110780\n",
      "Iteration 169, loss = 0.03056140\n",
      "Iteration 170, loss = 0.03002886\n",
      "Iteration 171, loss = 0.02950974\n",
      "Iteration 172, loss = 0.02900357\n",
      "Iteration 173, loss = 0.02850998\n",
      "Iteration 174, loss = 0.02802860\n",
      "Iteration 175, loss = 0.02755835\n",
      "Iteration 176, loss = 0.02709555\n",
      "Iteration 177, loss = 0.02663994\n",
      "Iteration 178, loss = 0.02619190\n",
      "Iteration 179, loss = 0.02575406\n",
      "Iteration 180, loss = 0.02532512\n",
      "Iteration 181, loss = 0.02490515\n",
      "Iteration 182, loss = 0.02449416\n",
      "Iteration 183, loss = 0.02409214\n",
      "Iteration 184, loss = 0.02370042\n",
      "Iteration 185, loss = 0.02331573\n",
      "Iteration 186, loss = 0.02293982\n",
      "Iteration 187, loss = 0.02257298\n",
      "Iteration 188, loss = 0.02221431\n",
      "Iteration 189, loss = 0.02186363\n",
      "Iteration 190, loss = 0.02152078\n",
      "Iteration 191, loss = 0.02118550\n",
      "Iteration 192, loss = 0.02085758\n",
      "Iteration 193, loss = 0.02053693\n",
      "Iteration 194, loss = 0.02022307\n",
      "Iteration 195, loss = 0.01991380\n",
      "Iteration 196, loss = 0.01960989\n",
      "Iteration 197, loss = 0.01931139\n",
      "Iteration 198, loss = 0.01901826\n",
      "Iteration 199, loss = 0.01873099\n",
      "Iteration 200, loss = 0.01844838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tthekkum/PycharmProjects/DS550/venv/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=5,\n             estimator=Pipeline(steps=[('tf', TfidfVectorizer()),\n                                       ('ann',\n                                        MLPClassifier(hidden_layer_sizes=[50,\n                                                                          15],\n                                                      verbose=True))]),\n             n_jobs=-1,\n             param_grid={'tf__max_features': [10, 20, 30],\n                         'tf__ngram_range': [(1, 1), (1, 2)],\n                         'tf__stop_words': ['english', None],\n                         'tf__use_idf': [True, False]})"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnnb.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnnb.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "{'tf__max_features': 10,\n 'tf__ngram_range': (1, 1),\n 'tf__stop_words': 'english',\n 'tf__use_idf': True}"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_mnnb.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "py_pred = gs_mnnb.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['sports', 'sports', 'sports', 'sports', 'sports', 'sports',\n       'sports', 'sports', 'sports', 'sports', 'sports', 'sports',\n       'sports', 'sports', 'sports', 'sports', 'sports', 'sports',\n       'sports', 'sports'], dtype='<U6')"
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#py_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "outputs": [
    {
     "data": {
      "text/plain": "37    sports\n62    sports\n83    sports\n14    sports\n43    sports\n9     sports\n44    sports\n31    sports\n69    sports\n57    sports\n33    sports\n87    sports\n12    sports\n91    sports\n41    sports\n23    sports\n76    sports\n29    sports\n50    sports\n68    sports\nName: cat, dtype: object"
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,py_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      sports       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,py_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, py_pred))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}